{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be4b4b47",
   "metadata": {},
   "source": [
    "## Doc2vec\n",
    "## Created by: Harsh Bari\n",
    "## From: SVNIT, Gujarat\n",
    "## Mtech Data Science - p23ds004 (2023-25)\n",
    "## Subject: NLP Project\n",
    "## Last Updated: 29/03/2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b09ebe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88a0faa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"resultant_train_dataframe_with_doc2vec.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a13ac88",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets_preprocessed</th>\n",
       "      <th>class</th>\n",
       "      <th>tokens</th>\n",
       "      <th>doc2vec_1</th>\n",
       "      <th>doc2vec_2</th>\n",
       "      <th>doc2vec_3</th>\n",
       "      <th>doc2vec_4</th>\n",
       "      <th>doc2vec_5</th>\n",
       "      <th>doc2vec_6</th>\n",
       "      <th>doc2vec_7</th>\n",
       "      <th>...</th>\n",
       "      <th>doc2vec_141</th>\n",
       "      <th>doc2vec_142</th>\n",
       "      <th>doc2vec_143</th>\n",
       "      <th>doc2vec_144</th>\n",
       "      <th>doc2vec_145</th>\n",
       "      <th>doc2vec_146</th>\n",
       "      <th>doc2vec_147</th>\n",
       "      <th>doc2vec_148</th>\n",
       "      <th>doc2vec_149</th>\n",
       "      <th>doc2vec_150</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aware dirty step get money staylight staywhite...</td>\n",
       "      <td>figurative</td>\n",
       "      <td>['aware', 'dirty', 'step', 'get', 'money', 'st...</td>\n",
       "      <td>0.094989</td>\n",
       "      <td>-0.130547</td>\n",
       "      <td>0.209554</td>\n",
       "      <td>-0.361079</td>\n",
       "      <td>-0.221886</td>\n",
       "      <td>-0.038969</td>\n",
       "      <td>0.067625</td>\n",
       "      <td>...</td>\n",
       "      <td>0.067937</td>\n",
       "      <td>0.004318</td>\n",
       "      <td>-0.190978</td>\n",
       "      <td>-0.127249</td>\n",
       "      <td>0.224521</td>\n",
       "      <td>0.286994</td>\n",
       "      <td>-0.408927</td>\n",
       "      <td>-0.023017</td>\n",
       "      <td>0.470415</td>\n",
       "      <td>-0.181644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sarcasm people nt understand diy artattack htt...</td>\n",
       "      <td>figurative</td>\n",
       "      <td>['sarcasm', 'people', 'nt', 'understand', 'diy...</td>\n",
       "      <td>0.141715</td>\n",
       "      <td>-0.156211</td>\n",
       "      <td>0.124129</td>\n",
       "      <td>-0.033891</td>\n",
       "      <td>0.164898</td>\n",
       "      <td>-0.043738</td>\n",
       "      <td>-0.018385</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.092888</td>\n",
       "      <td>0.069860</td>\n",
       "      <td>-0.055245</td>\n",
       "      <td>0.069266</td>\n",
       "      <td>0.308308</td>\n",
       "      <td>0.123551</td>\n",
       "      <td>-0.235466</td>\n",
       "      <td>-0.115437</td>\n",
       "      <td>0.039865</td>\n",
       "      <td>-0.139383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>iminworkjeremy medsingle dailymail reader sens...</td>\n",
       "      <td>figurative</td>\n",
       "      <td>['iminworkjeremy', 'medsingle', 'dailymail', '...</td>\n",
       "      <td>0.071912</td>\n",
       "      <td>-0.202637</td>\n",
       "      <td>0.029908</td>\n",
       "      <td>-0.157918</td>\n",
       "      <td>-0.128679</td>\n",
       "      <td>-0.045619</td>\n",
       "      <td>-0.104180</td>\n",
       "      <td>...</td>\n",
       "      <td>0.151252</td>\n",
       "      <td>-0.101986</td>\n",
       "      <td>0.282642</td>\n",
       "      <td>-0.086598</td>\n",
       "      <td>0.223873</td>\n",
       "      <td>0.174067</td>\n",
       "      <td>-0.169456</td>\n",
       "      <td>-0.119560</td>\n",
       "      <td>0.173128</td>\n",
       "      <td>-0.148945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wilw get feeling like game sarcasm</td>\n",
       "      <td>figurative</td>\n",
       "      <td>['wilw', 'get', 'feeling', 'like', 'game', 'sa...</td>\n",
       "      <td>-0.180418</td>\n",
       "      <td>0.049932</td>\n",
       "      <td>-0.014645</td>\n",
       "      <td>0.068700</td>\n",
       "      <td>0.355904</td>\n",
       "      <td>-0.015319</td>\n",
       "      <td>-0.081326</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.058158</td>\n",
       "      <td>0.159563</td>\n",
       "      <td>-0.068043</td>\n",
       "      <td>0.086269</td>\n",
       "      <td>-0.134709</td>\n",
       "      <td>0.099647</td>\n",
       "      <td>0.085780</td>\n",
       "      <td>-0.116880</td>\n",
       "      <td>-0.046430</td>\n",
       "      <td>0.040912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>teacherarthurg rweingarten probably missed tex...</td>\n",
       "      <td>figurative</td>\n",
       "      <td>['teacherarthurg', 'rweingarten', 'probably', ...</td>\n",
       "      <td>0.315940</td>\n",
       "      <td>-0.020790</td>\n",
       "      <td>-0.059559</td>\n",
       "      <td>-0.123925</td>\n",
       "      <td>-0.079683</td>\n",
       "      <td>-0.049342</td>\n",
       "      <td>-0.410057</td>\n",
       "      <td>...</td>\n",
       "      <td>0.079114</td>\n",
       "      <td>0.269202</td>\n",
       "      <td>-0.128115</td>\n",
       "      <td>-0.110087</td>\n",
       "      <td>0.058393</td>\n",
       "      <td>-0.061392</td>\n",
       "      <td>-0.255230</td>\n",
       "      <td>0.062121</td>\n",
       "      <td>0.095567</td>\n",
       "      <td>0.071325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81403</th>\n",
       "      <td>photo image via heart http tcoky8nf8z9oi child...</td>\n",
       "      <td>sarcasm</td>\n",
       "      <td>['photo', 'image', 'via', 'heart', 'http', 'tc...</td>\n",
       "      <td>-0.140894</td>\n",
       "      <td>0.102283</td>\n",
       "      <td>0.163148</td>\n",
       "      <td>-0.351250</td>\n",
       "      <td>0.024014</td>\n",
       "      <td>-0.074922</td>\n",
       "      <td>-0.064923</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.071322</td>\n",
       "      <td>-0.025431</td>\n",
       "      <td>0.296570</td>\n",
       "      <td>-0.411995</td>\n",
       "      <td>-0.025560</td>\n",
       "      <td>-0.040841</td>\n",
       "      <td>-0.118366</td>\n",
       "      <td>-0.020177</td>\n",
       "      <td>0.092701</td>\n",
       "      <td>-0.170328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81404</th>\n",
       "      <td>never knew better put universe lol maybe date ...</td>\n",
       "      <td>sarcasm</td>\n",
       "      <td>['never', 'knew', 'better', 'put', 'universe',...</td>\n",
       "      <td>-0.286387</td>\n",
       "      <td>0.332654</td>\n",
       "      <td>0.163479</td>\n",
       "      <td>0.022322</td>\n",
       "      <td>-0.029653</td>\n",
       "      <td>-0.245982</td>\n",
       "      <td>0.205693</td>\n",
       "      <td>...</td>\n",
       "      <td>0.508828</td>\n",
       "      <td>0.513158</td>\n",
       "      <td>-0.270504</td>\n",
       "      <td>0.309230</td>\n",
       "      <td>-0.017430</td>\n",
       "      <td>0.080909</td>\n",
       "      <td>-0.072816</td>\n",
       "      <td>-0.208270</td>\n",
       "      <td>-0.044189</td>\n",
       "      <td>-0.244862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81405</th>\n",
       "      <td>hey wanted say thanks puberty letting apart it...</td>\n",
       "      <td>sarcasm</td>\n",
       "      <td>['hey', 'wanted', 'say', 'thanks', 'puberty', ...</td>\n",
       "      <td>0.305770</td>\n",
       "      <td>-0.039960</td>\n",
       "      <td>-0.050912</td>\n",
       "      <td>-0.367826</td>\n",
       "      <td>0.106903</td>\n",
       "      <td>-0.123374</td>\n",
       "      <td>-0.111254</td>\n",
       "      <td>...</td>\n",
       "      <td>0.158231</td>\n",
       "      <td>0.562153</td>\n",
       "      <td>-0.630287</td>\n",
       "      <td>0.341704</td>\n",
       "      <td>-0.212747</td>\n",
       "      <td>0.195148</td>\n",
       "      <td>-0.224042</td>\n",
       "      <td>-0.335351</td>\n",
       "      <td>-0.049494</td>\n",
       "      <td>-0.149171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81406</th>\n",
       "      <td>sure coverage like fox news special hidden har...</td>\n",
       "      <td>sarcasm</td>\n",
       "      <td>['sure', 'coverage', 'like', 'fox', 'news', 's...</td>\n",
       "      <td>0.245714</td>\n",
       "      <td>-0.104332</td>\n",
       "      <td>-0.617117</td>\n",
       "      <td>0.092076</td>\n",
       "      <td>-0.238117</td>\n",
       "      <td>0.023707</td>\n",
       "      <td>-0.075002</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.178513</td>\n",
       "      <td>0.164409</td>\n",
       "      <td>0.197029</td>\n",
       "      <td>0.306697</td>\n",
       "      <td>-0.354954</td>\n",
       "      <td>-0.282870</td>\n",
       "      <td>-0.288228</td>\n",
       "      <td>0.156407</td>\n",
       "      <td>0.327664</td>\n",
       "      <td>-0.036328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81407</th>\n",
       "      <td>skeyno16 u13 wo nt believe see p sarcasm</td>\n",
       "      <td>sarcasm</td>\n",
       "      <td>['skeyno16', 'u13', 'wo', 'nt', 'believe', 'se...</td>\n",
       "      <td>-0.085722</td>\n",
       "      <td>-0.135554</td>\n",
       "      <td>-0.029625</td>\n",
       "      <td>0.010125</td>\n",
       "      <td>-0.025210</td>\n",
       "      <td>-0.266726</td>\n",
       "      <td>0.010516</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.130875</td>\n",
       "      <td>0.020180</td>\n",
       "      <td>0.041040</td>\n",
       "      <td>0.228905</td>\n",
       "      <td>0.157366</td>\n",
       "      <td>-0.026189</td>\n",
       "      <td>-0.168494</td>\n",
       "      <td>-0.246111</td>\n",
       "      <td>0.240429</td>\n",
       "      <td>-0.162665</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>81408 rows Ã— 153 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     tweets_preprocessed       class  \\\n",
       "0      aware dirty step get money staylight staywhite...  figurative   \n",
       "1      sarcasm people nt understand diy artattack htt...  figurative   \n",
       "2      iminworkjeremy medsingle dailymail reader sens...  figurative   \n",
       "3                     wilw get feeling like game sarcasm  figurative   \n",
       "4      teacherarthurg rweingarten probably missed tex...  figurative   \n",
       "...                                                  ...         ...   \n",
       "81403  photo image via heart http tcoky8nf8z9oi child...     sarcasm   \n",
       "81404  never knew better put universe lol maybe date ...     sarcasm   \n",
       "81405  hey wanted say thanks puberty letting apart it...     sarcasm   \n",
       "81406  sure coverage like fox news special hidden har...     sarcasm   \n",
       "81407           skeyno16 u13 wo nt believe see p sarcasm     sarcasm   \n",
       "\n",
       "                                                  tokens  doc2vec_1  \\\n",
       "0      ['aware', 'dirty', 'step', 'get', 'money', 'st...   0.094989   \n",
       "1      ['sarcasm', 'people', 'nt', 'understand', 'diy...   0.141715   \n",
       "2      ['iminworkjeremy', 'medsingle', 'dailymail', '...   0.071912   \n",
       "3      ['wilw', 'get', 'feeling', 'like', 'game', 'sa...  -0.180418   \n",
       "4      ['teacherarthurg', 'rweingarten', 'probably', ...   0.315940   \n",
       "...                                                  ...        ...   \n",
       "81403  ['photo', 'image', 'via', 'heart', 'http', 'tc...  -0.140894   \n",
       "81404  ['never', 'knew', 'better', 'put', 'universe',...  -0.286387   \n",
       "81405  ['hey', 'wanted', 'say', 'thanks', 'puberty', ...   0.305770   \n",
       "81406  ['sure', 'coverage', 'like', 'fox', 'news', 's...   0.245714   \n",
       "81407  ['skeyno16', 'u13', 'wo', 'nt', 'believe', 'se...  -0.085722   \n",
       "\n",
       "       doc2vec_2  doc2vec_3  doc2vec_4  doc2vec_5  doc2vec_6  doc2vec_7  ...  \\\n",
       "0      -0.130547   0.209554  -0.361079  -0.221886  -0.038969   0.067625  ...   \n",
       "1      -0.156211   0.124129  -0.033891   0.164898  -0.043738  -0.018385  ...   \n",
       "2      -0.202637   0.029908  -0.157918  -0.128679  -0.045619  -0.104180  ...   \n",
       "3       0.049932  -0.014645   0.068700   0.355904  -0.015319  -0.081326  ...   \n",
       "4      -0.020790  -0.059559  -0.123925  -0.079683  -0.049342  -0.410057  ...   \n",
       "...          ...        ...        ...        ...        ...        ...  ...   \n",
       "81403   0.102283   0.163148  -0.351250   0.024014  -0.074922  -0.064923  ...   \n",
       "81404   0.332654   0.163479   0.022322  -0.029653  -0.245982   0.205693  ...   \n",
       "81405  -0.039960  -0.050912  -0.367826   0.106903  -0.123374  -0.111254  ...   \n",
       "81406  -0.104332  -0.617117   0.092076  -0.238117   0.023707  -0.075002  ...   \n",
       "81407  -0.135554  -0.029625   0.010125  -0.025210  -0.266726   0.010516  ...   \n",
       "\n",
       "       doc2vec_141  doc2vec_142  doc2vec_143  doc2vec_144  doc2vec_145  \\\n",
       "0         0.067937     0.004318    -0.190978    -0.127249     0.224521   \n",
       "1        -0.092888     0.069860    -0.055245     0.069266     0.308308   \n",
       "2         0.151252    -0.101986     0.282642    -0.086598     0.223873   \n",
       "3        -0.058158     0.159563    -0.068043     0.086269    -0.134709   \n",
       "4         0.079114     0.269202    -0.128115    -0.110087     0.058393   \n",
       "...            ...          ...          ...          ...          ...   \n",
       "81403    -0.071322    -0.025431     0.296570    -0.411995    -0.025560   \n",
       "81404     0.508828     0.513158    -0.270504     0.309230    -0.017430   \n",
       "81405     0.158231     0.562153    -0.630287     0.341704    -0.212747   \n",
       "81406    -0.178513     0.164409     0.197029     0.306697    -0.354954   \n",
       "81407    -0.130875     0.020180     0.041040     0.228905     0.157366   \n",
       "\n",
       "       doc2vec_146  doc2vec_147  doc2vec_148  doc2vec_149  doc2vec_150  \n",
       "0         0.286994    -0.408927    -0.023017     0.470415    -0.181644  \n",
       "1         0.123551    -0.235466    -0.115437     0.039865    -0.139383  \n",
       "2         0.174067    -0.169456    -0.119560     0.173128    -0.148945  \n",
       "3         0.099647     0.085780    -0.116880    -0.046430     0.040912  \n",
       "4        -0.061392    -0.255230     0.062121     0.095567     0.071325  \n",
       "...            ...          ...          ...          ...          ...  \n",
       "81403    -0.040841    -0.118366    -0.020177     0.092701    -0.170328  \n",
       "81404     0.080909    -0.072816    -0.208270    -0.044189    -0.244862  \n",
       "81405     0.195148    -0.224042    -0.335351    -0.049494    -0.149171  \n",
       "81406    -0.282870    -0.288228     0.156407     0.327664    -0.036328  \n",
       "81407    -0.026189    -0.168494    -0.246111     0.240429    -0.162665  \n",
       "\n",
       "[81408 rows x 153 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54e3ea66",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = ['doc2vec_{}'.format(i) for i in range(1, 151)]\n",
    "input_vec = data[vec].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f992caa2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5deef9",
   "metadata": {},
   "source": [
    "### Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "850788ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_vec = np.array(input_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84be818f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(array_2d, ranges_to_copy):\n",
    "    copied_ranges = []\n",
    "\n",
    "    # Loop through each range and copy the corresponding elements\n",
    "    for start, end in ranges_to_copy:\n",
    "        copied_range = array_2d[start:end+1]  # Adjust end index to include the last element\n",
    "        copied_ranges.append(copied_range)\n",
    "\n",
    "    # Concatenate the copied ranges along the first axis to create the final array\n",
    "    copied_array = np.concatenate(copied_ranges, axis=0)\n",
    "\n",
    "    return copied_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee3e4e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = split_data(input_vec, [(0, 16989), (21238, 37952), (42132, 57007), (60727, 77270)])\n",
    "x_test = split_data(input_vec, [(16990, 21237), (37953, 42131), (57008, 60726), (77271, 81407)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7419b3b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x train: 65125\n",
      "x test: 16283\n",
      "Total: 81408\n"
     ]
    }
   ],
   "source": [
    "print(\"x train:\", len(x_train))\n",
    "print(\"x test:\", len(x_test))\n",
    "print(\"Total:\", len(x_train) + len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca72f713",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.concatenate((np.zeros(16990), np.ones(31591), np.zeros(16544)))\n",
    "y_test = np.concatenate((np.zeros(4248), np.ones(7898), np.zeros(4137)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "817a6e7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 65125\n",
      "test: 16283\n",
      "total: 81408\n"
     ]
    }
   ],
   "source": [
    "print(\"train:\", len(y_train))\n",
    "print(\"test:\", len(y_test))\n",
    "print(\"total:\", len(y_train) + len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a86a8be",
   "metadata": {},
   "source": [
    "## Training With Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "156e570a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Harsh Bari\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8cf696",
   "metadata": {},
   "source": [
    "### Neural Network for Average Word Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "393dd8fa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Harsh Bari\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Harsh Bari\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "d2v = keras.Sequential([\n",
    "    keras.layers.Dense(256, input_shape = (150, ), activation = 'relu'),\n",
    "    keras.layers.Dense(128, activation = 'relu'),\n",
    "    keras.layers.Dense(64, activation = 'relu'),\n",
    "    keras.layers.Dense(32, activation = 'relu'),\n",
    "    keras.layers.Dense(16, activation=keras.layers.LeakyReLU(alpha=0.1)),\n",
    "    keras.layers.Dense(8, activation=keras.layers.LeakyReLU(alpha=0.1)),\n",
    "    keras.layers.Dense(2, activation = 'sigmoid')\n",
    "\n",
    "])\n",
    "\n",
    "d2v.compile(optimizer = 'adam',\n",
    "                      loss = 'sparse_categorical_crossentropy',\n",
    "                      metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43a472f",
   "metadata": {},
   "source": [
    "keras.layers.Dense(110, activation = 'relu'),\n",
    "keras.layers.Dense(80, activation=keras.layers.LeakyReLU(alpha=0.1)),"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5595d08",
   "metadata": {},
   "source": [
    "### Check Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4c0ed5cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 256)               38656     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 16)                528       \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 2)                 18        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 82570 (322.54 KB)\n",
      "Trainable params: 82570 (322.54 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "d2v.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad032d88",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b6f0b15b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/22\n",
      "WARNING:tensorflow:From C:\\Users\\Harsh Bari\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Harsh Bari\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "2036/2036 [==============================] - 9s 3ms/step - loss: 0.4576 - accuracy: 0.7645\n",
      "Epoch 2/22\n",
      "2036/2036 [==============================] - 6s 3ms/step - loss: 0.3937 - accuracy: 0.7980\n",
      "Epoch 3/22\n",
      "2036/2036 [==============================] - 6s 3ms/step - loss: 0.3669 - accuracy: 0.8098\n",
      "Epoch 4/22\n",
      "2036/2036 [==============================] - 7s 3ms/step - loss: 0.3449 - accuracy: 0.8209\n",
      "Epoch 5/22\n",
      "2036/2036 [==============================] - 6s 3ms/step - loss: 0.3274 - accuracy: 0.8286\n",
      "Epoch 6/22\n",
      "2036/2036 [==============================] - 6s 3ms/step - loss: 0.3103 - accuracy: 0.8358\n",
      "Epoch 7/22\n",
      "2036/2036 [==============================] - 6s 3ms/step - loss: 0.2962 - accuracy: 0.8422\n",
      "Epoch 8/22\n",
      "2036/2036 [==============================] - 6s 3ms/step - loss: 0.2837 - accuracy: 0.8472\n",
      "Epoch 9/22\n",
      "2036/2036 [==============================] - 7s 3ms/step - loss: 0.2726 - accuracy: 0.8525\n",
      "Epoch 10/22\n",
      "2036/2036 [==============================] - 7s 3ms/step - loss: 0.2626 - accuracy: 0.8560\n",
      "Epoch 11/22\n",
      "2036/2036 [==============================] - 8s 4ms/step - loss: 0.2527 - accuracy: 0.8596\n",
      "Epoch 12/22\n",
      "2036/2036 [==============================] - 7s 3ms/step - loss: 0.2454 - accuracy: 0.8621\n",
      "Epoch 13/22\n",
      "2036/2036 [==============================] - 7s 3ms/step - loss: 0.2389 - accuracy: 0.8649\n",
      "Epoch 14/22\n",
      "2036/2036 [==============================] - 6s 3ms/step - loss: 0.2335 - accuracy: 0.8666\n",
      "Epoch 15/22\n",
      "2036/2036 [==============================] - 7s 3ms/step - loss: 0.2254 - accuracy: 0.8700\n",
      "Epoch 16/22\n",
      "2036/2036 [==============================] - 8s 4ms/step - loss: 0.2222 - accuracy: 0.8721\n",
      "Epoch 17/22\n",
      "2036/2036 [==============================] - 7s 3ms/step - loss: 0.2169 - accuracy: 0.8736\n",
      "Epoch 18/22\n",
      "2036/2036 [==============================] - 7s 3ms/step - loss: 0.2140 - accuracy: 0.8757\n",
      "Epoch 19/22\n",
      "2036/2036 [==============================] - 7s 3ms/step - loss: 0.2081 - accuracy: 0.8780\n",
      "Epoch 20/22\n",
      "2036/2036 [==============================] - 6s 3ms/step - loss: 0.2044 - accuracy: 0.8807\n",
      "Epoch 21/22\n",
      "2036/2036 [==============================] - 7s 3ms/step - loss: 0.2015 - accuracy: 0.8824\n",
      "Epoch 22/22\n",
      "2036/2036 [==============================] - 6s 3ms/step - loss: 0.1982 - accuracy: 0.8855\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x276278fbf10>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2v.fit(x_train.astype(np.float32), y_train.astype(np.float32), epochs=22)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db42192e",
   "metadata": {},
   "source": [
    "### Training Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8f0bfde0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2036/2036 [==============================] - 5s 2ms/step - loss: 0.1833 - accuracy: 0.8951\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.1832551509141922, 0.8951094150543213]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2v.evaluate(x_train.astype(np.float32), y_train.astype(np.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31685f2e",
   "metadata": {},
   "source": [
    "### Testing Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0793db67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "509/509 [==============================] - 2s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "prediction = d2v.predict(x_test.astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0090ab08",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = np.argmax(prediction, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "43679a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c632bb19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.78      0.80      8385\n",
      "         1.0       0.78      0.82      0.80      7898\n",
      "\n",
      "    accuracy                           0.80     16283\n",
      "   macro avg       0.80      0.80      0.80     16283\n",
      "weighted avg       0.80      0.80      0.80     16283\n",
      "\n",
      "\n",
      "Confusion Matrix: \n",
      " [[6541 1844]\n",
      " [1420 6478]]\n",
      "\n",
      "Accuracy: \n",
      " 0.7995455382914697\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test.astype(np.float32), prediction))\n",
    "print()\n",
    "print(\"Confusion Matrix: \\n\", confusion_matrix(y_test.astype(np.float32), prediction))\n",
    "print(\"\\nAccuracy: \\n\", accuracy_score(y_test.astype(np.float32), prediction))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
