{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dab99aa3",
   "metadata": {},
   "source": [
    "## Average Word Vector\n",
    "## Created by: Harsh Bari\n",
    "## From: SVNIT, Gujarat\n",
    "## Mtech Data Science - p23ds004 (2023-25)\n",
    "## Subject: NLP Project\n",
    "## Last Updated: 29/03/2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6d46132",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec132b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"final_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a423629a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>class</th>\n",
       "      <th>tokens</th>\n",
       "      <th>word2vec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Be aware  dirty step to get money  #staylight ...</td>\n",
       "      <td>figurative</td>\n",
       "      <td>['be', 'aware', 'dirty', 'step', 'to', 'get', ...</td>\n",
       "      <td>[-0.08192246  0.44799908  0.19038523 -0.092749...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>#sarcasm for #people who don't understand #diy...</td>\n",
       "      <td>figurative</td>\n",
       "      <td>['sarcasm', 'for', 'people', 'who', 'don', 'un...</td>\n",
       "      <td>[-0.39415668  0.14868878 -0.30105257 -0.247197...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@IminworkJeremy @medsingle #DailyMail readers ...</td>\n",
       "      <td>figurative</td>\n",
       "      <td>['iminworkjeremy', 'medsingle', 'dailymail', '...</td>\n",
       "      <td>[-0.38441235  0.36639656 -0.08122431  0.066615...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@wilw Why do I get the feeling you like games?...</td>\n",
       "      <td>figurative</td>\n",
       "      <td>['wilw', 'why', 'do', 'get', 'the', 'feeling',...</td>\n",
       "      <td>[-0.46358013  0.12668053  0.13927908  0.171643...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-@TeacherArthurG @rweingarten You probably jus...</td>\n",
       "      <td>figurative</td>\n",
       "      <td>['teacherarthurg', 'rweingarten', 'you', 'prob...</td>\n",
       "      <td>[-0.19652244  0.19875612 -0.15998856 -0.170760...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81403</th>\n",
       "      <td>Photo: Image via We Heart It http://t.co/ky8Nf...</td>\n",
       "      <td>sarcasm</td>\n",
       "      <td>['photo', 'image', 'via', 'we', 'heart', 'it',...</td>\n",
       "      <td>[-0.2547767   0.29173678  0.06745852  0.089999...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81404</th>\n",
       "      <td>I never knew..I better put this out to the Uni...</td>\n",
       "      <td>sarcasm</td>\n",
       "      <td>['never', 'knew', 'better', 'put', 'this', 'ou...</td>\n",
       "      <td>[-0.32126068  0.12298504  0.13224294  0.150191...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81405</th>\n",
       "      <td>hey just wanted to say thanks @ puberty for le...</td>\n",
       "      <td>sarcasm</td>\n",
       "      <td>['hey', 'just', 'wanted', 'to', 'say', 'thanks...</td>\n",
       "      <td>[-2.33878006e-01  1.36348982e-01 -7.76878343e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81406</th>\n",
       "      <td>I'm sure coverage like the Fox News Special “T...</td>\n",
       "      <td>sarcasm</td>\n",
       "      <td>['sure', 'coverage', 'like', 'the', 'fox', 'ne...</td>\n",
       "      <td>[-0.12494273  0.00411794  0.02370966  0.203509...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81407</th>\n",
       "      <td>@skeyno16 at u13?! I won't believe it until I ...</td>\n",
       "      <td>sarcasm</td>\n",
       "      <td>['skeyno', 'at', 'won', 'believe', 'it', 'unti...</td>\n",
       "      <td>[-0.0282643  -0.10591727  0.2379264   0.112892...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>81408 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  tweets       class  \\\n",
       "0      Be aware  dirty step to get money  #staylight ...  figurative   \n",
       "1      #sarcasm for #people who don't understand #diy...  figurative   \n",
       "2      @IminworkJeremy @medsingle #DailyMail readers ...  figurative   \n",
       "3      @wilw Why do I get the feeling you like games?...  figurative   \n",
       "4      -@TeacherArthurG @rweingarten You probably jus...  figurative   \n",
       "...                                                  ...         ...   \n",
       "81403  Photo: Image via We Heart It http://t.co/ky8Nf...     sarcasm   \n",
       "81404  I never knew..I better put this out to the Uni...     sarcasm   \n",
       "81405  hey just wanted to say thanks @ puberty for le...     sarcasm   \n",
       "81406  I'm sure coverage like the Fox News Special “T...     sarcasm   \n",
       "81407  @skeyno16 at u13?! I won't believe it until I ...     sarcasm   \n",
       "\n",
       "                                                  tokens  \\\n",
       "0      ['be', 'aware', 'dirty', 'step', 'to', 'get', ...   \n",
       "1      ['sarcasm', 'for', 'people', 'who', 'don', 'un...   \n",
       "2      ['iminworkjeremy', 'medsingle', 'dailymail', '...   \n",
       "3      ['wilw', 'why', 'do', 'get', 'the', 'feeling',...   \n",
       "4      ['teacherarthurg', 'rweingarten', 'you', 'prob...   \n",
       "...                                                  ...   \n",
       "81403  ['photo', 'image', 'via', 'we', 'heart', 'it',...   \n",
       "81404  ['never', 'knew', 'better', 'put', 'this', 'ou...   \n",
       "81405  ['hey', 'just', 'wanted', 'to', 'say', 'thanks...   \n",
       "81406  ['sure', 'coverage', 'like', 'the', 'fox', 'ne...   \n",
       "81407  ['skeyno', 'at', 'won', 'believe', 'it', 'unti...   \n",
       "\n",
       "                                                word2vec  \n",
       "0      [-0.08192246  0.44799908  0.19038523 -0.092749...  \n",
       "1      [-0.39415668  0.14868878 -0.30105257 -0.247197...  \n",
       "2      [-0.38441235  0.36639656 -0.08122431  0.066615...  \n",
       "3      [-0.46358013  0.12668053  0.13927908  0.171643...  \n",
       "4      [-0.19652244  0.19875612 -0.15998856 -0.170760...  \n",
       "...                                                  ...  \n",
       "81403  [-0.2547767   0.29173678  0.06745852  0.089999...  \n",
       "81404  [-0.32126068  0.12298504  0.13224294  0.150191...  \n",
       "81405  [-2.33878006e-01  1.36348982e-01 -7.76878343e-...  \n",
       "81406  [-0.12494273  0.00411794  0.02370966  0.203509...  \n",
       "81407  [-0.0282643  -0.10591727  0.2379264   0.112892...  \n",
       "\n",
       "[81408 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "403fcaff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [-0.08192246  0.44799908  0.19038523 -0.092749...\n",
       "1        [-0.39415668  0.14868878 -0.30105257 -0.247197...\n",
       "2        [-0.38441235  0.36639656 -0.08122431  0.066615...\n",
       "3        [-0.46358013  0.12668053  0.13927908  0.171643...\n",
       "4        [-0.19652244  0.19875612 -0.15998856 -0.170760...\n",
       "                               ...                        \n",
       "81403    [-0.2547767   0.29173678  0.06745852  0.089999...\n",
       "81404    [-0.32126068  0.12298504  0.13224294  0.150191...\n",
       "81405    [-2.33878006e-01  1.36348982e-01 -7.76878343e-...\n",
       "81406    [-0.12494273  0.00411794  0.02370966  0.203509...\n",
       "81407    [-0.0282643  -0.10591727  0.2379264   0.112892...\n",
       "Name: word2vec, Length: 81408, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['word2vec']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8952e2da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[-0.08192246  0.44799908  0.19038523 -0.09274998 -0.08060522  0.13320853\\n  0.21015547  0.15539696 -0.23566357  0.21636164  0.0283454   0.28280759\\n  0.17291894 -0.13524526  0.04833376 -0.2451405  -0.01642638 -0.07876031\\n -0.05630376  0.14641642  0.00160968  0.06245695 -0.37698133  0.08342589\\n  0.05364852 -0.04640223 -0.03445123 -0.09461063  0.23467198  0.0450404\\n  0.0438591   0.21541848  0.38158504 -0.06952128  0.2148452  -0.02609837\\n -0.07601524 -0.10320545  0.04465004  0.03037429 -0.08223748 -0.00512799\\n  0.31767438  0.09984008 -0.27293106 -0.0822356   0.04032159  0.13450514\\n -0.01024036  0.07759087 -0.13633434  0.39601669 -0.18086388  0.07863257\\n -0.12142318 -0.18982297 -0.13750716  0.02909118 -0.23583742 -0.04784711\\n  0.01999614  0.20932461  0.0254652   0.26366392  0.00856102  0.08058868\\n -0.20782008 -0.1359599  -0.23500545  0.03740927  0.11888506  0.17102422\\n  0.21671027  0.09068703 -0.25568805  0.02423541  0.11943042 -0.51753351\\n -0.16202727  0.22873774  0.06798634  0.22152784  0.0840674  -0.04993204\\n -0.26843767  0.07260146 -0.30092282  0.15355953 -0.0522157  -0.10862874\\n  0.04560524 -0.16612259 -0.06226176 -0.11781129 -0.07521048  0.00399866\\n  0.31480429  0.12684158  0.0491577   0.03760581 -0.12408901  0.16498946\\n  0.0691526   0.41420899 -0.31107269 -0.19319433 -0.04998738 -0.13795248\\n  0.01528367 -0.06783712 -0.02698278 -0.30714476 -0.04999141  0.15458899\\n -0.03083627  0.34201905  0.23672756  0.31692924  0.0461333  -0.08079044\\n -0.08898347  0.17961326 -0.38170894 -0.23787375 -0.10015603  0.22698843\\n -0.15538733  0.39900836  0.1796477  -0.05579911 -0.1960262   0.07388732\\n -0.18282236  0.13711534 -0.09072778  0.05247565  0.38945165  0.25997175\\n -0.39301072 -0.19569835 -0.176655   -0.01782703  0.07201633  0.11289259\\n  0.04637413 -0.17495102 -0.09149356  0.12997283  0.04181852  0.00232262]'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['word2vec'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92770fb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "figurative    21238\n",
       "irony         20894\n",
       "sarcasm       20681\n",
       "regular       18595\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9913f12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "print(type(data['word2vec'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25d079a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def str_to_vec(input_string):\n",
    "    # Your input string\n",
    "    # input_string = \"[ 0.47350284 0.17998783 0.52607228 -0.21903914 0.50474907 -0.84181457\\n 0.80536147 1.04832851 -0.31514828 -0.6643499 0.23167278 -0.84063938\\n -0.42383317 0.31786839 0.38651903 0.43740021 0.19098905 0.03756036\\n -0.37013237 -0.86544681 -0.60763254 -0.3359968 0.57907489 0.11688197\\n 0.51970026 -0.2024598 -0.29698118 -0.15100316 0.13487357 -0.38675231\\n 0.19580726 -0.21120347 -0.32096125 0.81528131 -0.12422152 -0.02690754\\n -0.01132907 0.1541235 0.69146074 0.26843169 0.6963023 -0.79966018\\n -0.21509953 -0.3805155 0.18800793 0.66235928 0.14572814 -0.41985339\\n -0.28700945 -0.28272397 0.25726554 -0.37221263 0.02272534 -0.4292531\\n -0.34494111 -0.10192458 -0.00632285 0.42416801 -0.18897754 -0.21455062\\n -0.80645763 0.41921128 0.23389137 0.17909839 -0.37738952 0.55195239\\n 0.03543126 -0.0540801 0.05538673 -0.29212652 -0.54393175 0.07931972\\n -0.01140794 0.89003169 -0.164462 -0.37368158 0.09018268 -0.305098\\n 0.14973728 0.44211518 -0.08145603 0.43468505 -0.74777054 0.15402889\\n 0.61750253 -0.09117783 0.61714293 0.33495427 -0.02995716 0.0333282\\n 0.71559205 -0.37184732 0.23758197 0.56563806 0.24524485 -0.22222566\\n 0.57311822 -0.14456244 -0.71279361 -0.51761399]\"\n",
    "\n",
    "    # Remove brackets and newline characters\n",
    "    cleaned_string = input_string.replace('[', '').replace(']', '').replace('\\n', '')\n",
    "\n",
    "    # Split the string into a list of strings\n",
    "    string_values = cleaned_string.split()\n",
    "\n",
    "    # Convert each string value to a float\n",
    "    float_values = [float(value) for value in string_values]\n",
    "\n",
    "    # Convert the list of floats to a NumPy array\n",
    "    vector = np.array(float_values)\n",
    "\n",
    "    # Now, 'vector' is a NumPy array representing your vector\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c77a2347",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a26a0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['word2vec'] = data['word2vec'].apply(str_to_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c4306a1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word2vec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-0.08192246, 0.44799908, 0.19038523, -0.09274...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[-0.39415668, 0.14868878, -0.30105257, -0.2471...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[-0.38441235, 0.36639656, -0.08122431, 0.06661...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[-0.46358013, 0.12668053, 0.13927908, 0.171643...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[-0.19652244, 0.19875612, -0.15998856, -0.1707...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81403</th>\n",
       "      <td>[-0.2547767, 0.29173678, 0.06745852, 0.0899995...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81404</th>\n",
       "      <td>[-0.32126068, 0.12298504, 0.13224294, 0.150191...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81405</th>\n",
       "      <td>[-0.233878006, 0.136348982, -0.0776878343, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81406</th>\n",
       "      <td>[-0.12494273, 0.00411794, 0.02370966, 0.203509...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81407</th>\n",
       "      <td>[-0.0282643, -0.10591727, 0.2379264, 0.1128929...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>81408 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                word2vec\n",
       "0      [-0.08192246, 0.44799908, 0.19038523, -0.09274...\n",
       "1      [-0.39415668, 0.14868878, -0.30105257, -0.2471...\n",
       "2      [-0.38441235, 0.36639656, -0.08122431, 0.06661...\n",
       "3      [-0.46358013, 0.12668053, 0.13927908, 0.171643...\n",
       "4      [-0.19652244, 0.19875612, -0.15998856, -0.1707...\n",
       "...                                                  ...\n",
       "81403  [-0.2547767, 0.29173678, 0.06745852, 0.0899995...\n",
       "81404  [-0.32126068, 0.12298504, 0.13224294, 0.150191...\n",
       "81405  [-0.233878006, 0.136348982, -0.0776878343, -0....\n",
       "81406  [-0.12494273, 0.00411794, 0.02370966, 0.203509...\n",
       "81407  [-0.0282643, -0.10591727, 0.2379264, 0.1128929...\n",
       "\n",
       "[81408 rows x 1 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b7c112da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81408\n"
     ]
    }
   ],
   "source": [
    "print(len(data['word2vec']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd93a013",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.08192246,  0.44799908,  0.19038523, -0.09274998, -0.08060522,\n",
       "        0.13320853,  0.21015547,  0.15539696, -0.23566357,  0.21636164,\n",
       "        0.0283454 ,  0.28280759,  0.17291894, -0.13524526,  0.04833376,\n",
       "       -0.2451405 , -0.01642638, -0.07876031, -0.05630376,  0.14641642,\n",
       "        0.00160968,  0.06245695, -0.37698133,  0.08342589,  0.05364852,\n",
       "       -0.04640223, -0.03445123, -0.09461063,  0.23467198,  0.0450404 ,\n",
       "        0.0438591 ,  0.21541848,  0.38158504, -0.06952128,  0.2148452 ,\n",
       "       -0.02609837, -0.07601524, -0.10320545,  0.04465004,  0.03037429,\n",
       "       -0.08223748, -0.00512799,  0.31767438,  0.09984008, -0.27293106,\n",
       "       -0.0822356 ,  0.04032159,  0.13450514, -0.01024036,  0.07759087,\n",
       "       -0.13633434,  0.39601669, -0.18086388,  0.07863257, -0.12142318,\n",
       "       -0.18982297, -0.13750716,  0.02909118, -0.23583742, -0.04784711,\n",
       "        0.01999614,  0.20932461,  0.0254652 ,  0.26366392,  0.00856102,\n",
       "        0.08058868, -0.20782008, -0.1359599 , -0.23500545,  0.03740927,\n",
       "        0.11888506,  0.17102422,  0.21671027,  0.09068703, -0.25568805,\n",
       "        0.02423541,  0.11943042, -0.51753351, -0.16202727,  0.22873774,\n",
       "        0.06798634,  0.22152784,  0.0840674 , -0.04993204, -0.26843767,\n",
       "        0.07260146, -0.30092282,  0.15355953, -0.0522157 , -0.10862874,\n",
       "        0.04560524, -0.16612259, -0.06226176, -0.11781129, -0.07521048,\n",
       "        0.00399866,  0.31480429,  0.12684158,  0.0491577 ,  0.03760581,\n",
       "       -0.12408901,  0.16498946,  0.0691526 ,  0.41420899, -0.31107269,\n",
       "       -0.19319433, -0.04998738, -0.13795248,  0.01528367, -0.06783712,\n",
       "       -0.02698278, -0.30714476, -0.04999141,  0.15458899, -0.03083627,\n",
       "        0.34201905,  0.23672756,  0.31692924,  0.0461333 , -0.08079044,\n",
       "       -0.08898347,  0.17961326, -0.38170894, -0.23787375, -0.10015603,\n",
       "        0.22698843, -0.15538733,  0.39900836,  0.1796477 , -0.05579911,\n",
       "       -0.1960262 ,  0.07388732, -0.18282236,  0.13711534, -0.09072778,\n",
       "        0.05247565,  0.38945165,  0.25997175, -0.39301072, -0.19569835,\n",
       "       -0.176655  , -0.01782703,  0.07201633,  0.11289259,  0.04637413,\n",
       "       -0.17495102, -0.09149356,  0.12997283,  0.04181852,  0.00232262])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['word2vec'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e21bbfe",
   "metadata": {},
   "source": [
    "### Create Input and Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "963f9f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_input_vectors(vector):\n",
    "    n = len(vector)\n",
    "    array_2d = np.empty((n, len(vector[0])), dtype=object)\n",
    "\n",
    "    # Create and insert 10 random 5D arrays into the 2D array\n",
    "    for i in range(n):\n",
    "        array_150d = vector[i]\n",
    "        array_2d[i] = array_150d\n",
    "\n",
    "    return array_2d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "17f55c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_vec = create_input_vectors(dataset['word2vec'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "99ac8be3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(input_vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "febbf2fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print(input_vec.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8227abc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_dict = {'figurative': 0, 'irony': 1, 'sarcasm': 1, 'regular': 0}\n",
    "\n",
    "# Use map to replace string values with numerical values\n",
    "output = data['class'].map(mapping_dict).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "309fd91d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(output.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c3ec5907",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "33ea304c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43bfd4b2",
   "metadata": {},
   "source": [
    "### Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "14535cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(array_2d, ranges_to_copy):\n",
    "    copied_ranges = []\n",
    "\n",
    "    # Loop through each range and copy the corresponding elements\n",
    "    for start, end in ranges_to_copy:\n",
    "        copied_range = array_2d[start:end+1]  # Adjust end index to include the last element\n",
    "        copied_ranges.append(copied_range)\n",
    "\n",
    "    # Concatenate the copied ranges along the first axis to create the final array\n",
    "    copied_array = np.concatenate(copied_ranges, axis=0)\n",
    "\n",
    "    return copied_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f524eeb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = split_data(input_vec, [(0, 16989), (21238, 37952), (42132, 57007), (60727, 77270)])\n",
    "x_test = split_data(input_vec, [(16990, 21237), (37953, 42131), (57008, 60726), (77271, 81407)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "28449c2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x train: 65125\n",
      "x test: 16283\n",
      "Total: 81408\n"
     ]
    }
   ],
   "source": [
    "print(\"x train:\", len(x_train))\n",
    "print(\"x test:\", len(x_test))\n",
    "print(\"Total:\", len(x_train) + len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "24eebbec",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.concatenate((np.zeros(16990), np.ones(31591), np.zeros(16544)))\n",
    "y_test = np.concatenate((np.zeros(4248), np.ones(7898), np.zeros(4137)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ad5fa155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 65125\n",
      "test: 16283\n",
      "total: 81408\n"
     ]
    }
   ],
   "source": [
    "print(\"train:\", len(y_train))\n",
    "print(\"test:\", len(y_test))\n",
    "print(\"total:\", len(y_train) + len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ba1dae",
   "metadata": {},
   "source": [
    "## Training With Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cf0b9de2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Harsh Bari\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2cb9a3a",
   "metadata": {},
   "source": [
    "### Neural Network for Average Word Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "094e0dc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Harsh Bari\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Harsh Bari\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "awe = keras.Sequential([\n",
    "    keras.layers.Dense(256, input_shape = (150, ), activation = 'relu'),\n",
    "    keras.layers.Dense(128, activation = 'relu'),\n",
    "    keras.layers.Dense(64, activation = 'relu'),\n",
    "    keras.layers.Dense(32, activation = 'relu'),\n",
    "    keras.layers.Dense(64, activation=keras.layers.LeakyReLU(alpha=0.1)),\n",
    "    keras.layers.Dense(32, activation=keras.layers.LeakyReLU(alpha=0.1)),\n",
    "    keras.layers.Dense(2, activation = 'sigmoid')\n",
    "])\n",
    "\n",
    "awe.compile(optimizer = 'adam',\n",
    "                      loss = 'sparse_categorical_crossentropy',\n",
    "                      metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8fab9f2",
   "metadata": {},
   "source": [
    "### Check Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6c29bb1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 256)               38656     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 64)                2112      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 2)                 66        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 86146 (336.51 KB)\n",
      "Trainable params: 86146 (336.51 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "awe.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0799bd",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "68a29ca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/22\n",
      "WARNING:tensorflow:From C:\\Users\\Harsh Bari\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Harsh Bari\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "2036/2036 [==============================] - 11s 4ms/step - loss: 0.3047 - accuracy: 0.8424\n",
      "Epoch 2/22\n",
      "2036/2036 [==============================] - 8s 4ms/step - loss: 0.2721 - accuracy: 0.8564\n",
      "Epoch 3/22\n",
      "2036/2036 [==============================] - 8s 4ms/step - loss: 0.2700 - accuracy: 0.8574\n",
      "Epoch 4/22\n",
      "2036/2036 [==============================] - 9s 4ms/step - loss: 0.2671 - accuracy: 0.8582\n",
      "Epoch 5/22\n",
      "2036/2036 [==============================] - 12s 6ms/step - loss: 0.2651 - accuracy: 0.8593\n",
      "Epoch 6/22\n",
      "2036/2036 [==============================] - 15s 7ms/step - loss: 0.2639 - accuracy: 0.8597\n",
      "Epoch 7/22\n",
      "2036/2036 [==============================] - 19s 9ms/step - loss: 0.2620 - accuracy: 0.8601\n",
      "Epoch 8/22\n",
      "2036/2036 [==============================] - 18s 9ms/step - loss: 0.2621 - accuracy: 0.8604\n",
      "Epoch 9/22\n",
      "2036/2036 [==============================] - 18s 9ms/step - loss: 0.2608 - accuracy: 0.8608\n",
      "Epoch 10/22\n",
      "2036/2036 [==============================] - 18s 9ms/step - loss: 0.2606 - accuracy: 0.8610\n",
      "Epoch 11/22\n",
      "2036/2036 [==============================] - 20s 10ms/step - loss: 0.2606 - accuracy: 0.8607\n",
      "Epoch 12/22\n",
      "2036/2036 [==============================] - 21s 10ms/step - loss: 0.2595 - accuracy: 0.8612\n",
      "Epoch 13/22\n",
      "2036/2036 [==============================] - 21s 11ms/step - loss: 0.2598 - accuracy: 0.8615\n",
      "Epoch 14/22\n",
      "2036/2036 [==============================] - 19s 9ms/step - loss: 0.2589 - accuracy: 0.8612\n",
      "Epoch 15/22\n",
      "2036/2036 [==============================] - 20s 10ms/step - loss: 0.2596 - accuracy: 0.8612\n",
      "Epoch 16/22\n",
      "2036/2036 [==============================] - 18s 9ms/step - loss: 0.2586 - accuracy: 0.8617\n",
      "Epoch 17/22\n",
      "2036/2036 [==============================] - 18s 9ms/step - loss: 0.2586 - accuracy: 0.8619\n",
      "Epoch 18/22\n",
      "2036/2036 [==============================] - 18s 9ms/step - loss: 0.2582 - accuracy: 0.8618\n",
      "Epoch 19/22\n",
      "2036/2036 [==============================] - 17s 8ms/step - loss: 0.2588 - accuracy: 0.8619\n",
      "Epoch 20/22\n",
      "2036/2036 [==============================] - 16s 8ms/step - loss: 0.2575 - accuracy: 0.8623\n",
      "Epoch 21/22\n",
      "2036/2036 [==============================] - 18s 9ms/step - loss: 0.2584 - accuracy: 0.8618\n",
      "Epoch 22/22\n",
      "2036/2036 [==============================] - 21s 10ms/step - loss: 0.2578 - accuracy: 0.8624\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x26a10157ca0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "awe.fit(x_train.astype(np.float32), y_train.astype(np.float32), epochs=22)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f32f7c4",
   "metadata": {},
   "source": [
    "### Training Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d3c319b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2036/2036 [==============================] - 18s 8ms/step - loss: 0.2587 - accuracy: 0.8622\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.25865301489830017, 0.86215740442276]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "awe.evaluate(x_train.astype(np.float32), y_train.astype(np.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47389ca",
   "metadata": {},
   "source": [
    "### Testing Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "156c7210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "509/509 [==============================] - 4s 7ms/step\n"
     ]
    }
   ],
   "source": [
    "prediction = awe.predict(x_test.astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "47314e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = np.argmax(prediction, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fba7a7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9c771ac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.79      0.88      8385\n",
      "         1.0       0.82      1.00      0.90      7898\n",
      "\n",
      "    accuracy                           0.89     16283\n",
      "   macro avg       0.91      0.89      0.89     16283\n",
      "weighted avg       0.91      0.89      0.89     16283\n",
      "\n",
      "\n",
      "Confusion Matrix: \n",
      " [[6637 1748]\n",
      " [  22 7876]]\n",
      "\n",
      "Accuracy: \n",
      " 0.8912976724190874\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test.astype(np.float32), prediction))\n",
    "print()\n",
    "print(\"Confusion Matrix: \\n\", confusion_matrix(y_test.astype(np.float32), prediction))\n",
    "print(\"\\nAccuracy: \\n\", accuracy_score(y_test.astype(np.float32), prediction))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
