{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5de1f5d",
   "metadata": {},
   "source": [
    "## Average Word Vector\n",
    "## Created by: Harsh Bari\n",
    "## From: SVNIT, Gujarat\n",
    "## Mtech Data Science - p23ds004 (2023-25)\n",
    "## Subject: NLP Project\n",
    "## Last Updated: 29/03/2024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0d067e",
   "metadata": {},
   "source": [
    "### 1) Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "346216a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee10009",
   "metadata": {},
   "source": [
    "### 2) Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc786b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee8c10e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Be aware  dirty step to get money  #staylight ...</td>\n",
       "      <td>figurative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>#sarcasm for #people who don't understand #diy...</td>\n",
       "      <td>figurative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@IminworkJeremy @medsingle #DailyMail readers ...</td>\n",
       "      <td>figurative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@wilw Why do I get the feeling you like games?...</td>\n",
       "      <td>figurative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-@TeacherArthurG @rweingarten You probably jus...</td>\n",
       "      <td>figurative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81403</th>\n",
       "      <td>Photo: Image via We Heart It http://t.co/ky8Nf...</td>\n",
       "      <td>sarcasm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81404</th>\n",
       "      <td>I never knew..I better put this out to the Uni...</td>\n",
       "      <td>sarcasm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81405</th>\n",
       "      <td>hey just wanted to say thanks @ puberty for le...</td>\n",
       "      <td>sarcasm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81406</th>\n",
       "      <td>I'm sure coverage like the Fox News Special “T...</td>\n",
       "      <td>sarcasm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81407</th>\n",
       "      <td>@skeyno16 at u13?! I won't believe it until I ...</td>\n",
       "      <td>sarcasm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>81408 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  tweets       class\n",
       "0      Be aware  dirty step to get money  #staylight ...  figurative\n",
       "1      #sarcasm for #people who don't understand #diy...  figurative\n",
       "2      @IminworkJeremy @medsingle #DailyMail readers ...  figurative\n",
       "3      @wilw Why do I get the feeling you like games?...  figurative\n",
       "4      -@TeacherArthurG @rweingarten You probably jus...  figurative\n",
       "...                                                  ...         ...\n",
       "81403  Photo: Image via We Heart It http://t.co/ky8Nf...     sarcasm\n",
       "81404  I never knew..I better put this out to the Uni...     sarcasm\n",
       "81405  hey just wanted to say thanks @ puberty for le...     sarcasm\n",
       "81406  I'm sure coverage like the Fox News Special “T...     sarcasm\n",
       "81407  @skeyno16 at u13?! I won't believe it until I ...     sarcasm\n",
       "\n",
       "[81408 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d6fb58a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "figurative    21238\n",
       "irony         20894\n",
       "sarcasm       20681\n",
       "regular       18595\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "142208ef",
   "metadata": {},
   "source": [
    "### 3) Preprocessing (cleaning and tokenizing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57381647",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_tweets = data.tweets.apply(gensim.utils.simple_preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9acd3604",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [be, aware, dirty, step, to, get, money, stayl...\n",
       "1        [sarcasm, for, people, who, don, understand, d...\n",
       "2        [iminworkjeremy, medsingle, dailymail, readers...\n",
       "3        [wilw, why, do, get, the, feeling, you, like, ...\n",
       "4        [teacherarthurg, rweingarten, you, probably, j...\n",
       "                               ...                        \n",
       "81403    [photo, image, via, we, heart, it, http, co, k...\n",
       "81404    [never, knew, better, put, this, out, to, the,...\n",
       "81405    [hey, just, wanted, to, say, thanks, puberty, ...\n",
       "81406    [sure, coverage, like, the, fox, news, special...\n",
       "81407    [skeyno, at, won, believe, it, until, see, it,...\n",
       "Name: tweets, Length: 81408, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5810ea7",
   "metadata": {},
   "source": [
    "### 4) Create Word2vec Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56e97d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "import gensim.downloader as api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0bea1654",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Initilize Model\n",
    "# model_cbow = gensim.models.Word2Vec(clean_tweets, workers=4, min_count=5, vector_size=150, window=5)\n",
    "\n",
    "# # workers = number of threads\n",
    "# # windows = number of words in considerations to predict the word similarity\n",
    "# # vector_size = number of features in input layer\n",
    "# # min_count = number of minimum words to consider the windows, if less than that then ignore that word(s)\n",
    "\n",
    "# # Build Vocabulary\n",
    "# model_cbow.build_vocab(clean_tweets, progress_per=1000)\n",
    "\n",
    "# # Train Model\n",
    "# model_cbow.train(clean_tweets, total_examples=model_cbow.corpus_count, epochs=model_cbow.epochs)\n",
    "\n",
    "# # to save the model and reuse it without training\n",
    "# # model_cbow.save(\"./word2vec_model.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "072ed223",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with open('wiki_model_1.bin', 'r') as f:\n",
    "        w_model_1 = gensim.models.KeyedVectors.load('wiki_model_1.bin')\n",
    "except FileNotFoundError:\n",
    "    wiki_model_1 = gensim.downloader.load('glove-wiki-gigaword-100')\n",
    "    wiki_model_1.save('wiki_model_1.bin')\n",
    "    w_model_1 = gensim.models.KeyedVectors.load('wiki_model_1.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4983523f",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with open('wiki_model_2.bin', 'r') as f:\n",
    "        w_model_2 = gensim.models.KeyedVectors.load('wiki_model_2.bin')\n",
    "except FileNotFoundError:\n",
    "    wiki_model_2 = gensim.downloader.load('glove-wiki-gigaword-50')\n",
    "    wiki_model_2.save('wiki_model_2.bin')\n",
    "    w_model_2 = gensim.models.KeyedVectors.load('wiki_model_2.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "05ce11b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load vector\n",
    "# model_w2v = gensim.models.ldamodel.LdaModel.load(\"word2vec_model.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6f58ea32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent_vec_w2v(sent):\n",
    "    vector_size_1 = 100\n",
    "    vector_size_2 = 50\n",
    "    \n",
    "    vec_1 = np.zeros(vector_size_1)\n",
    "    vec_2 = np.zeros(vector_size_2)\n",
    "    \n",
    "    ctr = 1\n",
    "    \n",
    "    for w in sent:\n",
    "        if w in w_model_1 and w in w_model_2:\n",
    "            ctr += 1\n",
    "            vec_1 += w_model_1[w][:vector_size_1]\n",
    "            vec_2 += w_model_1[w][:vector_size_2]\n",
    "            \n",
    "    wv_res = np.concatenate((vec_1, vec_2))\n",
    "    wv_res = wv_res/ctr\n",
    "     \n",
    "    return wv_res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b0951e",
   "metadata": {},
   "source": [
    "#### Save tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc4f266a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['tokens'] = clean_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2eb997b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>class</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Be aware  dirty step to get money  #staylight ...</td>\n",
       "      <td>figurative</td>\n",
       "      <td>[be, aware, dirty, step, to, get, money, stayl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>#sarcasm for #people who don't understand #diy...</td>\n",
       "      <td>figurative</td>\n",
       "      <td>[sarcasm, for, people, who, don, understand, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@IminworkJeremy @medsingle #DailyMail readers ...</td>\n",
       "      <td>figurative</td>\n",
       "      <td>[iminworkjeremy, medsingle, dailymail, readers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@wilw Why do I get the feeling you like games?...</td>\n",
       "      <td>figurative</td>\n",
       "      <td>[wilw, why, do, get, the, feeling, you, like, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-@TeacherArthurG @rweingarten You probably jus...</td>\n",
       "      <td>figurative</td>\n",
       "      <td>[teacherarthurg, rweingarten, you, probably, j...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81403</th>\n",
       "      <td>Photo: Image via We Heart It http://t.co/ky8Nf...</td>\n",
       "      <td>sarcasm</td>\n",
       "      <td>[photo, image, via, we, heart, it, http, co, k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81404</th>\n",
       "      <td>I never knew..I better put this out to the Uni...</td>\n",
       "      <td>sarcasm</td>\n",
       "      <td>[never, knew, better, put, this, out, to, the,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81405</th>\n",
       "      <td>hey just wanted to say thanks @ puberty for le...</td>\n",
       "      <td>sarcasm</td>\n",
       "      <td>[hey, just, wanted, to, say, thanks, puberty, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81406</th>\n",
       "      <td>I'm sure coverage like the Fox News Special “T...</td>\n",
       "      <td>sarcasm</td>\n",
       "      <td>[sure, coverage, like, the, fox, news, special...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81407</th>\n",
       "      <td>@skeyno16 at u13?! I won't believe it until I ...</td>\n",
       "      <td>sarcasm</td>\n",
       "      <td>[skeyno, at, won, believe, it, until, see, it,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>81408 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  tweets       class  \\\n",
       "0      Be aware  dirty step to get money  #staylight ...  figurative   \n",
       "1      #sarcasm for #people who don't understand #diy...  figurative   \n",
       "2      @IminworkJeremy @medsingle #DailyMail readers ...  figurative   \n",
       "3      @wilw Why do I get the feeling you like games?...  figurative   \n",
       "4      -@TeacherArthurG @rweingarten You probably jus...  figurative   \n",
       "...                                                  ...         ...   \n",
       "81403  Photo: Image via We Heart It http://t.co/ky8Nf...     sarcasm   \n",
       "81404  I never knew..I better put this out to the Uni...     sarcasm   \n",
       "81405  hey just wanted to say thanks @ puberty for le...     sarcasm   \n",
       "81406  I'm sure coverage like the Fox News Special “T...     sarcasm   \n",
       "81407  @skeyno16 at u13?! I won't believe it until I ...     sarcasm   \n",
       "\n",
       "                                                  tokens  \n",
       "0      [be, aware, dirty, step, to, get, money, stayl...  \n",
       "1      [sarcasm, for, people, who, don, understand, d...  \n",
       "2      [iminworkjeremy, medsingle, dailymail, readers...  \n",
       "3      [wilw, why, do, get, the, feeling, you, like, ...  \n",
       "4      [teacherarthurg, rweingarten, you, probably, j...  \n",
       "...                                                  ...  \n",
       "81403  [photo, image, via, we, heart, it, http, co, k...  \n",
       "81404  [never, knew, better, put, this, out, to, the,...  \n",
       "81405  [hey, just, wanted, to, say, thanks, puberty, ...  \n",
       "81406  [sure, coverage, like, the, fox, news, special...  \n",
       "81407  [skeyno, at, won, believe, it, until, see, it,...  \n",
       "\n",
       "[81408 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e869c25",
   "metadata": {},
   "source": [
    "### 5) Create vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5a8cdb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['word2vec'] = data['tokens'].apply(sent_vec_w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "878e5b19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>class</th>\n",
       "      <th>tokens</th>\n",
       "      <th>word2vec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Be aware  dirty step to get money  #staylight ...</td>\n",
       "      <td>figurative</td>\n",
       "      <td>[be, aware, dirty, step, to, get, money, stayl...</td>\n",
       "      <td>[-0.011905075838932624, 0.11662022568858586, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>#sarcasm for #people who don't understand #diy...</td>\n",
       "      <td>figurative</td>\n",
       "      <td>[sarcasm, for, people, who, don, understand, d...</td>\n",
       "      <td>[0.029422137746587397, 0.20814320296049119, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@IminworkJeremy @medsingle #DailyMail readers ...</td>\n",
       "      <td>figurative</td>\n",
       "      <td>[iminworkjeremy, medsingle, dailymail, readers...</td>\n",
       "      <td>[-0.1235885014757514, 0.05067412555217743, 0.3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@wilw Why do I get the feeling you like games?...</td>\n",
       "      <td>figurative</td>\n",
       "      <td>[wilw, why, do, get, the, feeling, you, like, ...</td>\n",
       "      <td>[-0.021854890137910844, 0.34805419892072675, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-@TeacherArthurG @rweingarten You probably jus...</td>\n",
       "      <td>figurative</td>\n",
       "      <td>[teacherarthurg, rweingarten, you, probably, j...</td>\n",
       "      <td>[-0.0528821237385273, 0.16415249928832054, 0.5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81403</th>\n",
       "      <td>Photo: Image via We Heart It http://t.co/ky8Nf...</td>\n",
       "      <td>sarcasm</td>\n",
       "      <td>[photo, image, via, we, heart, it, http, co, k...</td>\n",
       "      <td>[-0.1844358862274223, 0.18341966884003746, 0.3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81404</th>\n",
       "      <td>I never knew..I better put this out to the Uni...</td>\n",
       "      <td>sarcasm</td>\n",
       "      <td>[never, knew, better, put, this, out, to, the,...</td>\n",
       "      <td>[0.01726132275705988, 0.1990272288464687, 0.38...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81405</th>\n",
       "      <td>hey just wanted to say thanks @ puberty for le...</td>\n",
       "      <td>sarcasm</td>\n",
       "      <td>[hey, just, wanted, to, say, thanks, puberty, ...</td>\n",
       "      <td>[-7.330059357311414e-05, 0.011773303960976393,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81406</th>\n",
       "      <td>I'm sure coverage like the Fox News Special “T...</td>\n",
       "      <td>sarcasm</td>\n",
       "      <td>[sure, coverage, like, the, fox, news, special...</td>\n",
       "      <td>[-0.08389464654028415, 0.10088500231504441, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81407</th>\n",
       "      <td>@skeyno16 at u13?! I won't believe it until I ...</td>\n",
       "      <td>sarcasm</td>\n",
       "      <td>[skeyno, at, won, believe, it, until, see, it,...</td>\n",
       "      <td>[-0.02437943137354321, 0.19550255437692007, 0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>81408 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  tweets       class  \\\n",
       "0      Be aware  dirty step to get money  #staylight ...  figurative   \n",
       "1      #sarcasm for #people who don't understand #diy...  figurative   \n",
       "2      @IminworkJeremy @medsingle #DailyMail readers ...  figurative   \n",
       "3      @wilw Why do I get the feeling you like games?...  figurative   \n",
       "4      -@TeacherArthurG @rweingarten You probably jus...  figurative   \n",
       "...                                                  ...         ...   \n",
       "81403  Photo: Image via We Heart It http://t.co/ky8Nf...     sarcasm   \n",
       "81404  I never knew..I better put this out to the Uni...     sarcasm   \n",
       "81405  hey just wanted to say thanks @ puberty for le...     sarcasm   \n",
       "81406  I'm sure coverage like the Fox News Special “T...     sarcasm   \n",
       "81407  @skeyno16 at u13?! I won't believe it until I ...     sarcasm   \n",
       "\n",
       "                                                  tokens  \\\n",
       "0      [be, aware, dirty, step, to, get, money, stayl...   \n",
       "1      [sarcasm, for, people, who, don, understand, d...   \n",
       "2      [iminworkjeremy, medsingle, dailymail, readers...   \n",
       "3      [wilw, why, do, get, the, feeling, you, like, ...   \n",
       "4      [teacherarthurg, rweingarten, you, probably, j...   \n",
       "...                                                  ...   \n",
       "81403  [photo, image, via, we, heart, it, http, co, k...   \n",
       "81404  [never, knew, better, put, this, out, to, the,...   \n",
       "81405  [hey, just, wanted, to, say, thanks, puberty, ...   \n",
       "81406  [sure, coverage, like, the, fox, news, special...   \n",
       "81407  [skeyno, at, won, believe, it, until, see, it,...   \n",
       "\n",
       "                                                word2vec  \n",
       "0      [-0.011905075838932624, 0.11662022568858586, 0...  \n",
       "1      [0.029422137746587397, 0.20814320296049119, 0....  \n",
       "2      [-0.1235885014757514, 0.05067412555217743, 0.3...  \n",
       "3      [-0.021854890137910844, 0.34805419892072675, 0...  \n",
       "4      [-0.0528821237385273, 0.16415249928832054, 0.5...  \n",
       "...                                                  ...  \n",
       "81403  [-0.1844358862274223, 0.18341966884003746, 0.3...  \n",
       "81404  [0.01726132275705988, 0.1990272288464687, 0.38...  \n",
       "81405  [-7.330059357311414e-05, 0.011773303960976393,...  \n",
       "81406  [-0.08389464654028415, 0.10088500231504441, 0....  \n",
       "81407  [-0.02437943137354321, 0.19550255437692007, 0....  \n",
       "\n",
       "[81408 rows x 4 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8d424904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150\n"
     ]
    }
   ],
   "source": [
    "print(len(data['word2vec'][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67934d9",
   "metadata": {},
   "source": [
    "#### Save vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "570e564a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"final_dataset.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
