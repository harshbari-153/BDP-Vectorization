{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dab99aa3",
   "metadata": {},
   "source": [
    "## Average Word Vector\n",
    "## Created by: Harsh Bari\n",
    "## From: SVNIT, Gujarat\n",
    "## Mtech Data Science - p23ds004 (2023-25)\n",
    "## Subject: NLP Project\n",
    "## Last Updated: 29/03/2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6d46132",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec132b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"final_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a423629a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>class</th>\n",
       "      <th>tokens</th>\n",
       "      <th>word2vec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Be aware  dirty step to get money  #staylight ...</td>\n",
       "      <td>figurative</td>\n",
       "      <td>['be', 'aware', 'dirty', 'step', 'to', 'get', ...</td>\n",
       "      <td>[-1.19050758e-02  1.16620226e-01  1.97997382e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>#sarcasm for #people who don't understand #diy...</td>\n",
       "      <td>figurative</td>\n",
       "      <td>['sarcasm', 'for', 'people', 'who', 'don', 'un...</td>\n",
       "      <td>[ 2.94221377e-02  2.08143203e-01  1.72751102e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@IminworkJeremy @medsingle #DailyMail readers ...</td>\n",
       "      <td>figurative</td>\n",
       "      <td>['iminworkjeremy', 'medsingle', 'dailymail', '...</td>\n",
       "      <td>[-0.1235885   0.05067413  0.3733275  -0.227050...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@wilw Why do I get the feeling you like games?...</td>\n",
       "      <td>figurative</td>\n",
       "      <td>['wilw', 'why', 'do', 'get', 'the', 'feeling',...</td>\n",
       "      <td>[-0.02185489  0.3480542   0.624338   -0.582425...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-@TeacherArthurG @rweingarten You probably jus...</td>\n",
       "      <td>figurative</td>\n",
       "      <td>['teacherarthurg', 'rweingarten', 'you', 'prob...</td>\n",
       "      <td>[-0.05288212  0.1641525   0.54444376 -0.362433...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81403</th>\n",
       "      <td>Photo: Image via We Heart It http://t.co/ky8Nf...</td>\n",
       "      <td>sarcasm</td>\n",
       "      <td>['photo', 'image', 'via', 'we', 'heart', 'it',...</td>\n",
       "      <td>[-1.84435886e-01  1.83419669e-01  3.13743446e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81404</th>\n",
       "      <td>I never knew..I better put this out to the Uni...</td>\n",
       "      <td>sarcasm</td>\n",
       "      <td>['never', 'knew', 'better', 'put', 'this', 'ou...</td>\n",
       "      <td>[ 0.01726132  0.19902723  0.38343058 -0.256441...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81405</th>\n",
       "      <td>hey just wanted to say thanks @ puberty for le...</td>\n",
       "      <td>sarcasm</td>\n",
       "      <td>['hey', 'just', 'wanted', 'to', 'say', 'thanks...</td>\n",
       "      <td>[-7.33005936e-05  1.17733040e-02  3.56954102e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81406</th>\n",
       "      <td>I'm sure coverage like the Fox News Special “T...</td>\n",
       "      <td>sarcasm</td>\n",
       "      <td>['sure', 'coverage', 'like', 'the', 'fox', 'ne...</td>\n",
       "      <td>[-0.08389465  0.100885    0.36214375 -0.300751...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81407</th>\n",
       "      <td>@skeyno16 at u13?! I won't believe it until I ...</td>\n",
       "      <td>sarcasm</td>\n",
       "      <td>['skeyno', 'at', 'won', 'believe', 'it', 'unti...</td>\n",
       "      <td>[-0.02437943  0.19550255  0.49198555 -0.12781 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>81408 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  tweets       class  \\\n",
       "0      Be aware  dirty step to get money  #staylight ...  figurative   \n",
       "1      #sarcasm for #people who don't understand #diy...  figurative   \n",
       "2      @IminworkJeremy @medsingle #DailyMail readers ...  figurative   \n",
       "3      @wilw Why do I get the feeling you like games?...  figurative   \n",
       "4      -@TeacherArthurG @rweingarten You probably jus...  figurative   \n",
       "...                                                  ...         ...   \n",
       "81403  Photo: Image via We Heart It http://t.co/ky8Nf...     sarcasm   \n",
       "81404  I never knew..I better put this out to the Uni...     sarcasm   \n",
       "81405  hey just wanted to say thanks @ puberty for le...     sarcasm   \n",
       "81406  I'm sure coverage like the Fox News Special “T...     sarcasm   \n",
       "81407  @skeyno16 at u13?! I won't believe it until I ...     sarcasm   \n",
       "\n",
       "                                                  tokens  \\\n",
       "0      ['be', 'aware', 'dirty', 'step', 'to', 'get', ...   \n",
       "1      ['sarcasm', 'for', 'people', 'who', 'don', 'un...   \n",
       "2      ['iminworkjeremy', 'medsingle', 'dailymail', '...   \n",
       "3      ['wilw', 'why', 'do', 'get', 'the', 'feeling',...   \n",
       "4      ['teacherarthurg', 'rweingarten', 'you', 'prob...   \n",
       "...                                                  ...   \n",
       "81403  ['photo', 'image', 'via', 'we', 'heart', 'it',...   \n",
       "81404  ['never', 'knew', 'better', 'put', 'this', 'ou...   \n",
       "81405  ['hey', 'just', 'wanted', 'to', 'say', 'thanks...   \n",
       "81406  ['sure', 'coverage', 'like', 'the', 'fox', 'ne...   \n",
       "81407  ['skeyno', 'at', 'won', 'believe', 'it', 'unti...   \n",
       "\n",
       "                                                word2vec  \n",
       "0      [-1.19050758e-02  1.16620226e-01  1.97997382e-...  \n",
       "1      [ 2.94221377e-02  2.08143203e-01  1.72751102e-...  \n",
       "2      [-0.1235885   0.05067413  0.3733275  -0.227050...  \n",
       "3      [-0.02185489  0.3480542   0.624338   -0.582425...  \n",
       "4      [-0.05288212  0.1641525   0.54444376 -0.362433...  \n",
       "...                                                  ...  \n",
       "81403  [-1.84435886e-01  1.83419669e-01  3.13743446e-...  \n",
       "81404  [ 0.01726132  0.19902723  0.38343058 -0.256441...  \n",
       "81405  [-7.33005936e-05  1.17733040e-02  3.56954102e-...  \n",
       "81406  [-0.08389465  0.100885    0.36214375 -0.300751...  \n",
       "81407  [-0.02437943  0.19550255  0.49198555 -0.12781 ...  \n",
       "\n",
       "[81408 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "403fcaff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [-1.19050758e-02  1.16620226e-01  1.97997382e-...\n",
       "1        [ 2.94221377e-02  2.08143203e-01  1.72751102e-...\n",
       "2        [-0.1235885   0.05067413  0.3733275  -0.227050...\n",
       "3        [-0.02185489  0.3480542   0.624338   -0.582425...\n",
       "4        [-0.05288212  0.1641525   0.54444376 -0.362433...\n",
       "                               ...                        \n",
       "81403    [-1.84435886e-01  1.83419669e-01  3.13743446e-...\n",
       "81404    [ 0.01726132  0.19902723  0.38343058 -0.256441...\n",
       "81405    [-7.33005936e-05  1.17733040e-02  3.56954102e-...\n",
       "81406    [-0.08389465  0.100885    0.36214375 -0.300751...\n",
       "81407    [-0.02437943  0.19550255  0.49198555 -0.12781 ...\n",
       "Name: word2vec, Length: 81408, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['word2vec']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8952e2da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[-1.19050758e-02  1.16620226e-01  1.97997382e-01 -2.69489541e-01\\n -7.66756877e-02  1.27769003e-01 -2.55769373e-01  9.86336611e-02\\n  8.49334672e-02 -6.09500741e-02  1.84933924e-01  1.45254004e-01\\n -1.05722736e-03  4.07291507e-02  4.14199961e-02 -1.04670005e-01\\n  2.44177999e-01 -1.45667303e-01 -1.35545416e-01  2.11801241e-01\\n  2.27879851e-01  1.34966927e-02  1.13493863e-02 -8.83673140e-02\\n  3.29575739e-02  1.20378999e-01 -1.00660015e-02 -1.57044374e-01\\n  8.74430709e-02 -1.54583151e-01 -2.78526134e-02  3.28145041e-01\\n -2.69770028e-02  7.30823353e-03  2.09195139e-01  2.35272463e-01\\n -8.58561351e-03 -3.60043399e-02  1.22844919e-01  2.76703938e-02\\n -1.31999616e-01 -1.79826155e-01  4.65860034e-02 -3.88554156e-01\\n -2.14142157e-01  1.52666937e-02 -1.65338843e-01 -1.78316311e-01\\n  2.49726155e-02 -6.30770764e-01  4.04885411e-02 -6.33034941e-03\\n  1.35558544e-01  6.40117851e-01 -1.91852385e-01 -1.19760076e+00\\n  8.80471665e-02 -3.38173759e-02  7.96421535e-01 -2.04303846e-02\\n -2.09942308e-01  3.04531188e-01 -3.64052308e-01 -1.81030396e-01\\n  5.83005078e-01 -1.24062463e-01  3.68763313e-01  3.27876763e-01\\n  2.62113096e-02 -2.07590234e-01  6.34577597e-02 -2.89481154e-01\\n -1.36048535e-01 -2.46281767e-01 -7.24130926e-03 -2.36953685e-02\\n  5.65499784e-03 -4.31853690e-03 -3.92700460e-01 -8.04448489e-02\\n  3.75990149e-01 -6.47767699e-02 -1.60761079e-01  1.15441769e-01\\n -9.60930782e-01 -3.17082280e-02  8.96731489e-02  1.83563079e-01\\n -3.53253998e-01 -4.02852847e-01 -1.43927311e-01  1.59790049e-02\\n  4.14393749e-02 -1.46675996e-01  1.74810769e-01 -1.84741768e-01\\n  2.63673067e-02 -1.14777002e-01  1.20317925e-01  2.44135694e-01\\n -1.19050758e-02  1.16620226e-01  1.97997382e-01 -2.69489541e-01\\n -7.66756877e-02  1.27769003e-01 -2.55769373e-01  9.86336611e-02\\n  8.49334672e-02 -6.09500741e-02  1.84933924e-01  1.45254004e-01\\n -1.05722736e-03  4.07291507e-02  4.14199961e-02 -1.04670005e-01\\n  2.44177999e-01 -1.45667303e-01 -1.35545416e-01  2.11801241e-01\\n  2.27879851e-01  1.34966927e-02  1.13493863e-02 -8.83673140e-02\\n  3.29575739e-02  1.20378999e-01 -1.00660015e-02 -1.57044374e-01\\n  8.74430709e-02 -1.54583151e-01 -2.78526134e-02  3.28145041e-01\\n -2.69770028e-02  7.30823353e-03  2.09195139e-01  2.35272463e-01\\n -8.58561351e-03 -3.60043399e-02  1.22844919e-01  2.76703938e-02\\n -1.31999616e-01 -1.79826155e-01  4.65860034e-02 -3.88554156e-01\\n -2.14142157e-01  1.52666937e-02 -1.65338843e-01 -1.78316311e-01\\n  2.49726155e-02 -6.30770764e-01]'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['word2vec'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92770fb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "figurative    21238\n",
       "irony         20894\n",
       "sarcasm       20681\n",
       "regular       18595\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9913f12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "print(type(data['word2vec'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25d079a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def str_to_vec(input_string):\n",
    "    # Your input string\n",
    "    # input_string = \"[ 0.47350284 0.17998783 0.52607228 -0.21903914 0.50474907 -0.84181457\\n 0.80536147 1.04832851 -0.31514828 -0.6643499 0.23167278 -0.84063938\\n -0.42383317 0.31786839 0.38651903 0.43740021 0.19098905 0.03756036\\n -0.37013237 -0.86544681 -0.60763254 -0.3359968 0.57907489 0.11688197\\n 0.51970026 -0.2024598 -0.29698118 -0.15100316 0.13487357 -0.38675231\\n 0.19580726 -0.21120347 -0.32096125 0.81528131 -0.12422152 -0.02690754\\n -0.01132907 0.1541235 0.69146074 0.26843169 0.6963023 -0.79966018\\n -0.21509953 -0.3805155 0.18800793 0.66235928 0.14572814 -0.41985339\\n -0.28700945 -0.28272397 0.25726554 -0.37221263 0.02272534 -0.4292531\\n -0.34494111 -0.10192458 -0.00632285 0.42416801 -0.18897754 -0.21455062\\n -0.80645763 0.41921128 0.23389137 0.17909839 -0.37738952 0.55195239\\n 0.03543126 -0.0540801 0.05538673 -0.29212652 -0.54393175 0.07931972\\n -0.01140794 0.89003169 -0.164462 -0.37368158 0.09018268 -0.305098\\n 0.14973728 0.44211518 -0.08145603 0.43468505 -0.74777054 0.15402889\\n 0.61750253 -0.09117783 0.61714293 0.33495427 -0.02995716 0.0333282\\n 0.71559205 -0.37184732 0.23758197 0.56563806 0.24524485 -0.22222566\\n 0.57311822 -0.14456244 -0.71279361 -0.51761399]\"\n",
    "\n",
    "    # Remove brackets and newline characters\n",
    "    cleaned_string = input_string.replace('[', '').replace(']', '').replace('\\n', '')\n",
    "\n",
    "    # Split the string into a list of strings\n",
    "    string_values = cleaned_string.split()\n",
    "\n",
    "    # Convert each string value to a float\n",
    "    float_values = [float(value) for value in string_values]\n",
    "\n",
    "    # Convert the list of floats to a NumPy array\n",
    "    vector = np.array(float_values)\n",
    "\n",
    "    # Now, 'vector' is a NumPy array representing your vector\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c77a2347",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a26a0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['word2vec'] = data['word2vec'].apply(str_to_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c4306a1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word2vec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-0.0119050758, 0.116620226, 0.197997382, -0.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.0294221377, 0.208143203, 0.172751102, -0.41...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[-0.1235885, 0.05067413, 0.3733275, -0.2270506...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[-0.02185489, 0.3480542, 0.624338, -0.582425, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[-0.05288212, 0.1641525, 0.54444376, -0.362433...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81403</th>\n",
       "      <td>[-0.184435886, 0.183419669, 0.313743446, -0.29...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81404</th>\n",
       "      <td>[0.01726132, 0.19902723, 0.38343058, -0.256441...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81405</th>\n",
       "      <td>[-7.33005936e-05, 0.011773304, 0.356954102, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81406</th>\n",
       "      <td>[-0.08389465, 0.100885, 0.36214375, -0.3007513...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81407</th>\n",
       "      <td>[-0.02437943, 0.19550255, 0.49198555, -0.12781...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>81408 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                word2vec\n",
       "0      [-0.0119050758, 0.116620226, 0.197997382, -0.2...\n",
       "1      [0.0294221377, 0.208143203, 0.172751102, -0.41...\n",
       "2      [-0.1235885, 0.05067413, 0.3733275, -0.2270506...\n",
       "3      [-0.02185489, 0.3480542, 0.624338, -0.582425, ...\n",
       "4      [-0.05288212, 0.1641525, 0.54444376, -0.362433...\n",
       "...                                                  ...\n",
       "81403  [-0.184435886, 0.183419669, 0.313743446, -0.29...\n",
       "81404  [0.01726132, 0.19902723, 0.38343058, -0.256441...\n",
       "81405  [-7.33005936e-05, 0.011773304, 0.356954102, -0...\n",
       "81406  [-0.08389465, 0.100885, 0.36214375, -0.3007513...\n",
       "81407  [-0.02437943, 0.19550255, 0.49198555, -0.12781...\n",
       "\n",
       "[81408 rows x 1 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b7c112da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81408\n"
     ]
    }
   ],
   "source": [
    "print(len(data['word2vec']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd93a013",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.19050758e-02,  1.16620226e-01,  1.97997382e-01, -2.69489541e-01,\n",
       "       -7.66756877e-02,  1.27769003e-01, -2.55769373e-01,  9.86336611e-02,\n",
       "        8.49334672e-02, -6.09500741e-02,  1.84933924e-01,  1.45254004e-01,\n",
       "       -1.05722736e-03,  4.07291507e-02,  4.14199961e-02, -1.04670005e-01,\n",
       "        2.44177999e-01, -1.45667303e-01, -1.35545416e-01,  2.11801241e-01,\n",
       "        2.27879851e-01,  1.34966927e-02,  1.13493863e-02, -8.83673140e-02,\n",
       "        3.29575739e-02,  1.20378999e-01, -1.00660015e-02, -1.57044374e-01,\n",
       "        8.74430709e-02, -1.54583151e-01, -2.78526134e-02,  3.28145041e-01,\n",
       "       -2.69770028e-02,  7.30823353e-03,  2.09195139e-01,  2.35272463e-01,\n",
       "       -8.58561351e-03, -3.60043399e-02,  1.22844919e-01,  2.76703938e-02,\n",
       "       -1.31999616e-01, -1.79826155e-01,  4.65860034e-02, -3.88554156e-01,\n",
       "       -2.14142157e-01,  1.52666937e-02, -1.65338843e-01, -1.78316311e-01,\n",
       "        2.49726155e-02, -6.30770764e-01,  4.04885411e-02, -6.33034941e-03,\n",
       "        1.35558544e-01,  6.40117851e-01, -1.91852385e-01, -1.19760076e+00,\n",
       "        8.80471665e-02, -3.38173759e-02,  7.96421535e-01, -2.04303846e-02,\n",
       "       -2.09942308e-01,  3.04531188e-01, -3.64052308e-01, -1.81030396e-01,\n",
       "        5.83005078e-01, -1.24062463e-01,  3.68763313e-01,  3.27876763e-01,\n",
       "        2.62113096e-02, -2.07590234e-01,  6.34577597e-02, -2.89481154e-01,\n",
       "       -1.36048535e-01, -2.46281767e-01, -7.24130926e-03, -2.36953685e-02,\n",
       "        5.65499784e-03, -4.31853690e-03, -3.92700460e-01, -8.04448489e-02,\n",
       "        3.75990149e-01, -6.47767699e-02, -1.60761079e-01,  1.15441769e-01,\n",
       "       -9.60930782e-01, -3.17082280e-02,  8.96731489e-02,  1.83563079e-01,\n",
       "       -3.53253998e-01, -4.02852847e-01, -1.43927311e-01,  1.59790049e-02,\n",
       "        4.14393749e-02, -1.46675996e-01,  1.74810769e-01, -1.84741768e-01,\n",
       "        2.63673067e-02, -1.14777002e-01,  1.20317925e-01,  2.44135694e-01,\n",
       "       -1.19050758e-02,  1.16620226e-01,  1.97997382e-01, -2.69489541e-01,\n",
       "       -7.66756877e-02,  1.27769003e-01, -2.55769373e-01,  9.86336611e-02,\n",
       "        8.49334672e-02, -6.09500741e-02,  1.84933924e-01,  1.45254004e-01,\n",
       "       -1.05722736e-03,  4.07291507e-02,  4.14199961e-02, -1.04670005e-01,\n",
       "        2.44177999e-01, -1.45667303e-01, -1.35545416e-01,  2.11801241e-01,\n",
       "        2.27879851e-01,  1.34966927e-02,  1.13493863e-02, -8.83673140e-02,\n",
       "        3.29575739e-02,  1.20378999e-01, -1.00660015e-02, -1.57044374e-01,\n",
       "        8.74430709e-02, -1.54583151e-01, -2.78526134e-02,  3.28145041e-01,\n",
       "       -2.69770028e-02,  7.30823353e-03,  2.09195139e-01,  2.35272463e-01,\n",
       "       -8.58561351e-03, -3.60043399e-02,  1.22844919e-01,  2.76703938e-02,\n",
       "       -1.31999616e-01, -1.79826155e-01,  4.65860034e-02, -3.88554156e-01,\n",
       "       -2.14142157e-01,  1.52666937e-02, -1.65338843e-01, -1.78316311e-01,\n",
       "        2.49726155e-02, -6.30770764e-01])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['word2vec'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e21bbfe",
   "metadata": {},
   "source": [
    "### Create Input and Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "963f9f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_input_vectors(vector):\n",
    "    n = len(vector)\n",
    "    array_2d = np.empty((n, len(vector[0])), dtype=object)\n",
    "\n",
    "    # Create and insert 10 random 5D arrays into the 2D array\n",
    "    for i in range(n):\n",
    "        array_150d = vector[i]\n",
    "        array_2d[i] = array_150d\n",
    "\n",
    "    return array_2d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "17f55c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_vec = create_input_vectors(dataset['word2vec'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "99ac8be3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(input_vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "febbf2fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print(input_vec.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8227abc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_dict = {'figurative': 0, 'irony': 1, 'sarcasm': 1, 'regular': 0}\n",
    "\n",
    "# Use map to replace string values with numerical values\n",
    "output = data['class'].map(mapping_dict).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "309fd91d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(output.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c3ec5907",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "33ea304c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43bfd4b2",
   "metadata": {},
   "source": [
    "### Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "14535cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(array_2d, ranges_to_copy):\n",
    "    copied_ranges = []\n",
    "\n",
    "    # Loop through each range and copy the corresponding elements\n",
    "    for start, end in ranges_to_copy:\n",
    "        copied_range = array_2d[start:end+1]  # Adjust end index to include the last element\n",
    "        copied_ranges.append(copied_range)\n",
    "\n",
    "    # Concatenate the copied ranges along the first axis to create the final array\n",
    "    copied_array = np.concatenate(copied_ranges, axis=0)\n",
    "\n",
    "    return copied_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f524eeb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = split_data(input_vec, [(0, 16989), (21238, 37952), (42132, 57007), (60727, 77270)])\n",
    "x_test = split_data(input_vec, [(16990, 21237), (37953, 42131), (57008, 60726), (77271, 81407)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "28449c2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x train: 65125\n",
      "x test: 16283\n",
      "Total: 81408\n"
     ]
    }
   ],
   "source": [
    "print(\"x train:\", len(x_train))\n",
    "print(\"x test:\", len(x_test))\n",
    "print(\"Total:\", len(x_train) + len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "24eebbec",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.concatenate((np.zeros(16990), np.ones(31591), np.zeros(16544)))\n",
    "y_test = np.concatenate((np.zeros(4248), np.ones(7898), np.zeros(4137)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ad5fa155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 65125\n",
      "test: 16283\n",
      "total: 81408\n"
     ]
    }
   ],
   "source": [
    "print(\"train:\", len(y_train))\n",
    "print(\"test:\", len(y_test))\n",
    "print(\"total:\", len(y_train) + len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ba1dae",
   "metadata": {},
   "source": [
    "## Training With Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cf0b9de2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Harsh Bari\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2cb9a3a",
   "metadata": {},
   "source": [
    "### Neural Network for Average Word Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "094e0dc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Harsh Bari\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Harsh Bari\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "awe = keras.Sequential([\n",
    "    keras.layers.Dense(256, input_shape = (150, ), activation = 'relu'),\n",
    "    keras.layers.Dense(128, activation = 'relu'),\n",
    "    keras.layers.Dense(64, activation = 'relu'),\n",
    "    keras.layers.Dense(32, activation = 'relu'),\n",
    "    keras.layers.Dense(16, activation=keras.layers.LeakyReLU(alpha=0.1)),\n",
    "    keras.layers.Dense(8, activation=keras.layers.LeakyReLU(alpha=0.1)),\n",
    "    keras.layers.Dense(2, activation = 'sigmoid')\n",
    "\n",
    "])\n",
    "\n",
    "awe.compile(optimizer = 'adam',\n",
    "                      loss = 'sparse_categorical_crossentropy',\n",
    "                      metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8fab9f2",
   "metadata": {},
   "source": [
    "### Check Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6c29bb1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 256)               38656     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 16)                528       \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 2)                 18        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 82570 (322.54 KB)\n",
      "Trainable params: 82570 (322.54 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "awe.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0799bd",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "68a29ca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/22\n",
      "WARNING:tensorflow:From C:\\Users\\Harsh Bari\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Harsh Bari\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "2036/2036 [==============================] - 9s 3ms/step - loss: 0.4297 - accuracy: 0.7776\n",
      "Epoch 2/22\n",
      "2036/2036 [==============================] - 6s 3ms/step - loss: 0.3914 - accuracy: 0.7971\n",
      "Epoch 3/22\n",
      "2036/2036 [==============================] - 7s 3ms/step - loss: 0.3798 - accuracy: 0.8028\n",
      "Epoch 4/22\n",
      "2036/2036 [==============================] - 6s 3ms/step - loss: 0.3720 - accuracy: 0.8065\n",
      "Epoch 5/22\n",
      "2036/2036 [==============================] - 7s 3ms/step - loss: 0.3656 - accuracy: 0.8086\n",
      "Epoch 6/22\n",
      "2036/2036 [==============================] - 8s 4ms/step - loss: 0.3604 - accuracy: 0.8100\n",
      "Epoch 7/22\n",
      "2036/2036 [==============================] - 7s 4ms/step - loss: 0.3548 - accuracy: 0.8144\n",
      "Epoch 8/22\n",
      "2036/2036 [==============================] - 8s 4ms/step - loss: 0.3515 - accuracy: 0.8161\n",
      "Epoch 9/22\n",
      "2036/2036 [==============================] - 7s 4ms/step - loss: 0.3474 - accuracy: 0.8168\n",
      "Epoch 10/22\n",
      "2036/2036 [==============================] - 7s 4ms/step - loss: 0.3418 - accuracy: 0.8205\n",
      "Epoch 11/22\n",
      "2036/2036 [==============================] - 8s 4ms/step - loss: 0.3394 - accuracy: 0.8204\n",
      "Epoch 12/22\n",
      "2036/2036 [==============================] - 8s 4ms/step - loss: 0.3360 - accuracy: 0.8218\n",
      "Epoch 13/22\n",
      "2036/2036 [==============================] - 7s 4ms/step - loss: 0.3330 - accuracy: 0.8238\n",
      "Epoch 14/22\n",
      "2036/2036 [==============================] - 6s 3ms/step - loss: 0.3288 - accuracy: 0.8249\n",
      "Epoch 15/22\n",
      "2036/2036 [==============================] - 7s 3ms/step - loss: 0.3270 - accuracy: 0.8267\n",
      "Epoch 16/22\n",
      "2036/2036 [==============================] - 7s 3ms/step - loss: 0.3246 - accuracy: 0.8276\n",
      "Epoch 17/22\n",
      "2036/2036 [==============================] - 6s 3ms/step - loss: 0.3209 - accuracy: 0.8284\n",
      "Epoch 18/22\n",
      "2036/2036 [==============================] - 6s 3ms/step - loss: 0.3189 - accuracy: 0.8294\n",
      "Epoch 19/22\n",
      "2036/2036 [==============================] - 7s 3ms/step - loss: 0.3160 - accuracy: 0.8310\n",
      "Epoch 20/22\n",
      "2036/2036 [==============================] - 6s 3ms/step - loss: 0.3138 - accuracy: 0.8318\n",
      "Epoch 21/22\n",
      "2036/2036 [==============================] - 7s 4ms/step - loss: 0.3112 - accuracy: 0.8324\n",
      "Epoch 22/22\n",
      "2036/2036 [==============================] - 7s 3ms/step - loss: 0.3084 - accuracy: 0.8348\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1aff962e1d0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "awe.fit(x_train.astype(np.float32), y_train.astype(np.float32), epochs=22)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f32f7c4",
   "metadata": {},
   "source": [
    "### Training Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d3c319b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2036/2036 [==============================] - 5s 2ms/step - loss: 0.3047 - accuracy: 0.8377\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.30468904972076416, 0.837727427482605]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "awe.evaluate(x_train.astype(np.float32), y_train.astype(np.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47389ca",
   "metadata": {},
   "source": [
    "### Testing Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "156c7210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "509/509 [==============================] - 2s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "prediction = awe.predict(x_test.astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "47314e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = np.argmax(prediction, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fba7a7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9c771ac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.76      0.83      8385\n",
      "         1.0       0.78      0.91      0.84      7898\n",
      "\n",
      "    accuracy                           0.84     16283\n",
      "   macro avg       0.84      0.84      0.83     16283\n",
      "weighted avg       0.84      0.84      0.83     16283\n",
      "\n",
      "\n",
      "Confusion Matrix: \n",
      " [[6407 1978]\n",
      " [ 703 7195]]\n",
      "\n",
      "Accuracy: \n",
      " 0.8353497512743352\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test.astype(np.float32), prediction))\n",
    "print()\n",
    "print(\"Confusion Matrix: \\n\", confusion_matrix(y_test.astype(np.float32), prediction))\n",
    "print(\"\\nAccuracy: \\n\", accuracy_score(y_test.astype(np.float32), prediction))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
